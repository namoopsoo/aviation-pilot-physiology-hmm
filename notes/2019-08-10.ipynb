{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick notes from tesnorboard video\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4&feature=youtu.be&t=97\n",
    "\n",
    "```\n",
    "# tf.summary.FileWriter(n):\n",
    "# classthat writes data for tensorboard..\n",
    "\n",
    "writer = tf.summary.FileWriter(\"/tmp/blah/1\")\n",
    "writer.add_graph(sess.graph)\n",
    "```\n",
    "* And run ... \n",
    "```\n",
    "tensorboard --logdir /tmp/mnist_demo/1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boiler plate\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import ipdb\n",
    "import mytf.utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.executing_eagerly())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/2019-07-21T1815-UTC-outdata-SUBSET50k.pkl', 'rb') as fd:\n",
    "    julydata = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_indices = np.arange(0, julydata['x_train'].shape[0], 1)\n",
    "training_indices.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training indices... (50000,)\n",
      "Start build v3: .. doesnt add up to 1.0\n",
      "num slices 50\n",
      "size_remainder,  0\n",
      "Counter({0: 519, 2: 416, 3: 51, 1: 14})\n",
      "weights_per_class,  Tensor(\"truediv:0\", shape=(4,), dtype=float32)\n",
      "1004.1999999999998\n",
      "Counter({0: 514, 2: 408, 3: 54, 1: 24})\n",
      "weights_per_class,  Tensor(\"truediv_1:0\", shape=(4,), dtype=float32)\n",
      "1007.1999999999995\n",
      "Counter({0: 528, 2: 396, 3: 54, 1: 22})\n",
      "weights_per_class,  Tensor(\"truediv_2:0\", shape=(4,), dtype=float32)\n",
      "1006.5999999999997\n",
      "Counter({0: 519, 2: 417, 3: 48, 1: 16})\n",
      "weights_per_class,  Tensor(\"truediv_3:0\", shape=(4,), dtype=float32)\n",
      "1004.8\n",
      "Counter({0: 527, 2: 408, 3: 53, 1: 12})\n",
      "weights_per_class,  Tensor(\"truediv_4:0\", shape=(4,), dtype=float32)\n",
      "1003.5999999999997\n",
      "Counter({0: 527, 2: 410, 3: 48, 1: 15})\n",
      "weights_per_class,  Tensor(\"truediv_5:0\", shape=(4,), dtype=float32)\n",
      "1004.4999999999997\n",
      "Counter({0: 542, 2: 381, 3: 62, 1: 15})\n",
      "weights_per_class,  Tensor(\"truediv_6:0\", shape=(4,), dtype=float32)\n",
      "1004.4999999999997\n",
      "Counter({0: 503, 2: 425, 3: 54, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_7:0\", shape=(4,), dtype=float32)\n",
      "1005.3999999999996\n",
      "Counter({0: 516, 2: 417, 3: 48, 1: 19})\n",
      "weights_per_class,  Tensor(\"truediv_8:0\", shape=(4,), dtype=float32)\n",
      "1005.6999999999997\n",
      "Counter({0: 530, 2: 405, 3: 44, 1: 21})\n",
      "weights_per_class,  Tensor(\"truediv_9:0\", shape=(4,), dtype=float32)\n",
      "1006.2999999999996\n",
      "Counter({0: 516, 2: 402, 3: 62, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_10:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999997\n",
      "Counter({0: 532, 2: 405, 3: 47, 1: 16})\n",
      "weights_per_class,  Tensor(\"truediv_11:0\", shape=(4,), dtype=float32)\n",
      "1004.8\n",
      "Counter({0: 512, 2: 406, 3: 58, 1: 24})\n",
      "weights_per_class,  Tensor(\"truediv_12:0\", shape=(4,), dtype=float32)\n",
      "1007.1999999999994\n",
      "Counter({0: 519, 2: 403, 3: 61, 1: 17})\n",
      "weights_per_class,  Tensor(\"truediv_13:0\", shape=(4,), dtype=float32)\n",
      "1005.0999999999997\n",
      "Counter({0: 546, 2: 394, 3: 43, 1: 17})\n",
      "weights_per_class,  Tensor(\"truediv_14:0\", shape=(4,), dtype=float32)\n",
      "1005.0999999999995\n",
      "Counter({0: 537, 2: 405, 3: 42, 1: 16})\n",
      "weights_per_class,  Tensor(\"truediv_15:0\", shape=(4,), dtype=float32)\n",
      "1004.7999999999997\n",
      "Counter({0: 499, 2: 439, 3: 52, 1: 10})\n",
      "weights_per_class,  Tensor(\"truediv_16:0\", shape=(4,), dtype=float32)\n",
      "1002.9999999999998\n",
      "Counter({0: 527, 2: 411, 3: 47, 1: 15})\n",
      "weights_per_class,  Tensor(\"truediv_17:0\", shape=(4,), dtype=float32)\n",
      "1004.4999999999995\n",
      "Counter({0: 535, 2: 393, 3: 53, 1: 19})\n",
      "weights_per_class,  Tensor(\"truediv_18:0\", shape=(4,), dtype=float32)\n",
      "1005.6999999999996\n",
      "Counter({0: 522, 2: 403, 3: 57, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_19:0\", shape=(4,), dtype=float32)\n",
      "1005.3999999999996\n",
      "Counter({0: 530, 2: 408, 3: 49, 1: 13})\n",
      "weights_per_class,  Tensor(\"truediv_20:0\", shape=(4,), dtype=float32)\n",
      "1003.8999999999997\n",
      "Counter({0: 500, 2: 426, 3: 48, 1: 26})\n",
      "weights_per_class,  Tensor(\"truediv_21:0\", shape=(4,), dtype=float32)\n",
      "1007.7999999999996\n",
      "Counter({0: 523, 2: 401, 3: 51, 1: 25})\n",
      "weights_per_class,  Tensor(\"truediv_22:0\", shape=(4,), dtype=float32)\n",
      "1007.4999999999998\n",
      "Counter({0: 498, 2: 427, 3: 55, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_23:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999995\n",
      "Counter({0: 505, 2: 424, 3: 54, 1: 17})\n",
      "weights_per_class,  Tensor(\"truediv_24:0\", shape=(4,), dtype=float32)\n",
      "1005.0999999999996\n",
      "Counter({0: 545, 2: 395, 3: 44, 1: 16})\n",
      "weights_per_class,  Tensor(\"truediv_25:0\", shape=(4,), dtype=float32)\n",
      "1004.7999999999998\n",
      "Counter({0: 522, 2: 403, 3: 56, 1: 19})\n",
      "weights_per_class,  Tensor(\"truediv_26:0\", shape=(4,), dtype=float32)\n",
      "1005.6999999999996\n",
      "Counter({0: 550, 2: 376, 3: 55, 1: 19})\n",
      "weights_per_class,  Tensor(\"truediv_27:0\", shape=(4,), dtype=float32)\n",
      "1005.6999999999998\n",
      "Counter({0: 500, 2: 431, 3: 49, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_28:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999995\n",
      "Counter({0: 552, 2: 383, 3: 51, 1: 14})\n",
      "weights_per_class,  Tensor(\"truediv_29:0\", shape=(4,), dtype=float32)\n",
      "1004.1999999999998\n",
      "Counter({0: 516, 2: 409, 3: 60, 1: 15})\n",
      "weights_per_class,  Tensor(\"truediv_30:0\", shape=(4,), dtype=float32)\n",
      "1004.4999999999995\n",
      "Counter({0: 559, 2: 371, 3: 47, 1: 23})\n",
      "weights_per_class,  Tensor(\"truediv_31:0\", shape=(4,), dtype=float32)\n",
      "1006.8999999999994\n",
      "Counter({0: 499, 2: 429, 3: 52, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_32:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999998\n",
      "Counter({0: 553, 2: 380, 3: 47, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_33:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999997\n",
      "Counter({0: 536, 2: 406, 3: 37, 1: 21})\n",
      "weights_per_class,  Tensor(\"truediv_34:0\", shape=(4,), dtype=float32)\n",
      "1006.2999999999995\n",
      "Counter({0: 536, 2: 390, 3: 50, 1: 24})\n",
      "weights_per_class,  Tensor(\"truediv_35:0\", shape=(4,), dtype=float32)\n",
      "1007.1999999999994\n",
      "Counter({0: 520, 2: 413, 3: 47, 1: 20})\n",
      "weights_per_class,  Tensor(\"truediv_36:0\", shape=(4,), dtype=float32)\n",
      "1005.9999999999998\n",
      "Counter({0: 532, 2: 398, 3: 51, 1: 19})\n",
      "weights_per_class,  Tensor(\"truediv_37:0\", shape=(4,), dtype=float32)\n",
      "1005.6999999999996\n",
      "Counter({0: 523, 2: 410, 3: 50, 1: 17})\n",
      "weights_per_class,  Tensor(\"truediv_38:0\", shape=(4,), dtype=float32)\n",
      "1005.0999999999996\n",
      "Counter({0: 548, 2: 379, 3: 61, 1: 12})\n",
      "weights_per_class,  Tensor(\"truediv_39:0\", shape=(4,), dtype=float32)\n",
      "1003.5999999999997\n",
      "Counter({0: 519, 2: 410, 3: 53, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_40:0\", shape=(4,), dtype=float32)\n",
      "1005.3999999999996\n",
      "Counter({0: 533, 2: 392, 3: 54, 1: 21})\n",
      "weights_per_class,  Tensor(\"truediv_41:0\", shape=(4,), dtype=float32)\n",
      "1006.2999999999995\n",
      "Counter({0: 523, 2: 404, 3: 61, 1: 12})\n",
      "weights_per_class,  Tensor(\"truediv_42:0\", shape=(4,), dtype=float32)\n",
      "1003.5999999999998\n",
      "Counter({0: 493, 2: 435, 3: 56, 1: 16})\n",
      "weights_per_class,  Tensor(\"truediv_43:0\", shape=(4,), dtype=float32)\n",
      "1004.7999999999997\n",
      "Counter({0: 522, 2: 414, 3: 49, 1: 15})\n",
      "weights_per_class,  Tensor(\"truediv_44:0\", shape=(4,), dtype=float32)\n",
      "1004.4999999999999\n",
      "Counter({0: 541, 2: 390, 3: 51, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_45:0\", shape=(4,), dtype=float32)\n",
      "1005.3999999999996\n",
      "Counter({0: 531, 2: 400, 3: 59, 1: 10})\n",
      "weights_per_class,  Tensor(\"truediv_46:0\", shape=(4,), dtype=float32)\n",
      "1002.9999999999999\n",
      "Counter({0: 540, 2: 378, 3: 64, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_47:0\", shape=(4,), dtype=float32)\n",
      "1005.3999999999996\n",
      "Counter({0: 538, 2: 388, 3: 51, 1: 23})\n",
      "weights_per_class,  Tensor(\"truediv_48:0\", shape=(4,), dtype=float32)\n",
      "1006.8999999999996\n",
      "Counter({0: 510, 2: 425, 3: 47, 1: 18})\n",
      "weights_per_class,  Tensor(\"truediv_49:0\", shape=(4,), dtype=float32)\n",
      "1005.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = {0: 1.0, 1: 1.3, 2: 1.0, 3: 1.0}\n",
    "training_indices = np.arange(0, julydata['x_train'].shape[0], 1)\n",
    "print('training indices...', training_indices.shape)\n",
    "\n",
    "dataset_batches = mu.build_dataset_weighty_v3(\n",
    "    julydata,\n",
    "    training_indices, \n",
    "    class_weights,\n",
    "    batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/LeDropbox/Dropbox/Code/Kaggle/reducing-commercial-aviation-fatalities/mytf/utils.py\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(model, dataset_batches)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    207\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # okay... now try use that ..\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64,   dropout=0.2, recurrent_dropout=0.2,\n",
    "                    batch_input_shape=(None, 256, 3), \n",
    "                  ),\n",
    "        # 4 because 'A', 'B', 'C', 'D'.\n",
    "        tf.keras.layers.Dense(4)\n",
    "    ])\n",
    "\n",
    "    %time loss_history = mu.do_train(model, dataset_batches)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ddf3115bdcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5459\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5460\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5461\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/pandars3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5515\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5516\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5517\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5518\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grr, so that kind of sucks that I got this error ...\n",
    "\n",
    "```\n",
    "RuntimeError: dataset.__iter__() is only supported when eager execution is enabled.\n",
    "```\n",
    "\n",
    "I guess this means the dataset tooling I was using cannot be used \n",
    "for both eager and non-eager exeuction. \n",
    "\n",
    "Looking at the code from the youtube tutorial, https://github.com/martinwicke/tf-dev-summit-tensorboard-tutorial/blob/master/mnist.py\n",
    "batches are iterated using this `next_batch(100)`\n",
    "\n",
    "```python\n",
    "for i in range(2001):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "```\n",
    "\n",
    "But I tried that on my dataset and the next_batch function was not implemented \n",
    "for the dataset that I built using \n",
    "\n",
    "```python\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_tensor, label_tensor, weights_tensor))\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
