{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Previously sorted train.csv \n",
    "#     using df.sort_values(by=['crew', 'experiment', 'time'])\n",
    "df = pd.read_csv('data/sorted_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crew                  1\n",
       "experiment           CA\n",
       "time          0.0117188\n",
       "seat                  1\n",
       "eeg_fp1        -5.28545\n",
       "eeg_f7          26.7758\n",
       "eeg_f8         -9.52731\n",
       "eeg_t4         -12.7932\n",
       "eeg_t6          16.7178\n",
       "eeg_t5          33.7375\n",
       "eeg_t3          23.7123\n",
       "eeg_fp2        -6.69587\n",
       "eeg_o1          29.2321\n",
       "eeg_p3          24.8429\n",
       "eeg_pz          3.92134\n",
       "eeg_f3           18.447\n",
       "eeg_fz          1.07547\n",
       "eeg_f4          3.09029\n",
       "eeg_c4           37.369\n",
       "eeg_p4          17.4376\n",
       "eeg_poz         19.2019\n",
       "eeg_c3          20.5968\n",
       "eeg_cz         -3.95115\n",
       "eeg_o2          14.5076\n",
       "ecg               -4520\n",
       "r               817.706\n",
       "gsr              388.83\n",
       "event                 A\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4867421, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_records(dfx):\n",
    "    return [(int(x), y) for (x,y) in json.loads(dfx['time'].to_json(orient='columns')).items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crew</th>\n",
       "      <th>seat</th>\n",
       "      <th>time</th>\n",
       "      <th>r</th>\n",
       "      <th>experiment</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109.988281</td>\n",
       "      <td>817.437988</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.988281</td>\n",
       "      <td>664.265991</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.992188</td>\n",
       "      <td>664.265991</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109.992188</td>\n",
       "      <td>817.442017</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109.996094</td>\n",
       "      <td>817.442017</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.996094</td>\n",
       "      <td>664.265991</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>664.331970</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>817.898987</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.003906</td>\n",
       "      <td>664.331970</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.003906</td>\n",
       "      <td>817.898987</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.007812</td>\n",
       "      <td>664.281982</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.007812</td>\n",
       "      <td>817.898987</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.011719</td>\n",
       "      <td>664.281982</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.011719</td>\n",
       "      <td>817.898987</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.015625</td>\n",
       "      <td>664.281982</td>\n",
       "      <td>CA</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crew  seat        time           r experiment event\n",
       "6600     1     1  109.988281  817.437988         CA     C\n",
       "6601     1     0  109.988281  664.265991         CA     C\n",
       "6602     1     0  109.992188  664.265991         CA     C\n",
       "6603     1     1  109.992188  817.442017         CA     C\n",
       "6604     1     1  109.996094  817.442017         CA     C\n",
       "6605     1     0  109.996094  664.265991         CA     C\n",
       "6606     1     0   11.000000  664.331970         CA     C\n",
       "6607     1     1   11.000000  817.898987         CA     C\n",
       "6608     1     0   11.003906  664.331970         CA     C\n",
       "6609     1     1   11.003906  817.898987         CA     C\n",
       "6610     1     0   11.007812  664.281982         CA     C\n",
       "6611     1     1   11.007812  817.898987         CA     C\n",
       "6612     1     0   11.011719  664.281982         CA     C\n",
       "6613     1     1   11.011719  817.898987         CA     C\n",
       "6614     1     0   11.015625  664.281982         CA     C"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        df[['crew', 'seat', 'time', 'r', 'experiment', 'event']].iloc[6600:6615]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92131, 28)\n",
      "(92077, 28)\n",
      "(39563, 28)\n",
      "(92168, 28)\n",
      "(92130, 28)\n",
      "(39583, 28)\n",
      "(92133, 28)\n",
      "(92194, 28)\n",
      "(92131, 28)\n",
      "(92099, 28)\n",
      "(92099, 28)\n",
      "(92212, 28)\n"
     ]
    }
   ],
   "source": [
    "choices = ([1,2], [0,1], ['CA', 'DA', 'SS'])\n",
    "for crew, seat, experiment in itertools.product(*choices):\n",
    "    query = (df.crew == crew)&(df.seat == seat)& (df.experiment == experiment)\n",
    "    print(df[query].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4721, 4)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_y(encode_class(y_train), 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4721 samples, validate on 243 samples\n",
      "Epoch 1/2\n",
      " - 38s - loss: 0.9748 - acc: 0.7672 - val_loss: 0.2220 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      " - 39s - loss: 0.6874 - acc: 0.7766 - val_loss: 0.1880 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# initial toy model w/ just a handful of inputs.\n",
    "model = bake_model(x_train, reshape_y(encode_class(y_train), 4),\n",
    "                   x_test, reshape_y(encode_class(y_test), 4), epochs=2)\n",
    "# y2 = reshape_y(y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[:5])\n",
    "predict_classes = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.3049076 , -0.2723024 ,  0.67816526, -0.01257241],\n",
       "        [ 0.3049076 , -0.2723024 ,  0.67816526, -0.01257241],\n",
       "        [ 0.3049076 , -0.2723024 ,  0.67816526, -0.01257241],\n",
       "        [ 0.3049076 , -0.2723024 ,  0.67816526, -0.01257241],\n",
       "        [ 0.30490765, -0.27230242,  0.6781652 , -0.0125725 ]],\n",
       "       dtype=float32),\n",
       " array([2, 2, 2, 2, 2]),\n",
       " array(['A', 'A', 'A', 'A', 'A'], dtype='<U1'))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, predict_classes, y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 256, 1)\n",
      "[[665.0020139999998]\n",
      " [665.0020139999998]\n",
      " [665.0020139999998]\n",
      " [665.0020139999998]\n",
      " [665.0020139999998]]\n",
      "(221,)\n",
      "Counter({0: 221})\n"
     ]
    }
   ],
   "source": [
    "trainseqs.shape, yarray.shape\n",
    "print(trainseqs.shape)\n",
    "# print(np.resize(trainseqs, (221, 256, 1)).shape) \n",
    "print(trainseqs[0][:5])\n",
    "print(yarray.shape)\n",
    "\n",
    "print(Counter(encode_class(yarray)))\n",
    "# print (type(yarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.867421e+06\n",
       "mean     7.376090e+02\n",
       "std      8.187979e+01\n",
       "min      4.820600e+02\n",
       "25%      6.631430e+02\n",
       "50%      7.434380e+02\n",
       "75%      8.134120e+02\n",
       "max      8.401840e+02\n",
       "Name: r, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.r.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start make_data 2019-05-16 13:41:08\n",
      "Start building training set 2019-05-16 13:41:08\n",
      "Start building testing set 2019-05-16 13:41:09\n",
      "Start bake_model 2019-05-16 13:41:10\n",
      "Train... 2019-05-16 13:41:11\n",
      "Train on 91874 samples, validate on 91876 samples\n",
      "Epoch 1/2\n",
      " - 874s - loss: 0.1881 - acc: 0.1129 - val_loss: 1.0480e-07 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      " - 893s - loss: 0.1271 - acc: 0.0466 - val_loss: 1.0480e-07 - val_acc: 0.0000e+00\n",
      "CPU times: user 1h 18min 13s, sys: 32min 39s, total: 1h 50min 53s\n",
      "Wall time: 29min 30s\n"
     ]
    }
   ],
   "source": [
    "# First model train, \n",
    "%time out, model = runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building training set 2019-05-16 14:57:24\n",
      "Start building testing set 2019-05-16 14:57:25\n"
     ]
    }
   ],
   "source": [
    "# (Running make_data() one more time to get additional intermediate data) \n",
    "outdata = make_data(df, crews={'training': [1],\n",
    "                        'test': [2]},\n",
    "              sequence_window=256, row_cap_per_person=None,\n",
    "             feature_cols={'r': simple_scaler})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x15133e2b0> (91876, 256, 1) (91876, 4)\n",
      "pred[:5] [[-1.1603819  -0.6849162   4.523494   -0.68110585]\n",
      " [-1.1603718  -0.684935    4.523487   -0.6811167 ]\n",
      " [-1.1603596  -0.6849571   4.523492   -0.6811271 ]\n",
      " [-1.1603528  -0.6849684   4.523488   -0.68113387]\n",
      " [-1.1603469  -0.68497616  4.523484   -0.68113863]]\n",
      "predict classes[:5] [2 2 2 2 2]\n",
      "y test [[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "y test original ['C' 'C' 'C' 'C' 'C']\n",
      "Counter y test original Counter({'C': 91876})\n",
      "Counter predict classes Counter({'C': 91876})\n"
     ]
    }
   ],
   "source": [
    "# Review that model...\n",
    "print(model, out['x_test'].shape, out['y_test'].shape)\n",
    "pred = model.predict(out['x_test'])\n",
    "predict_classes = np.argmax(pred, axis=1)\n",
    "print('pred[:5]', pred[:5])\n",
    "print('predict classes[:5]', predict_classes[:5])\n",
    "print('y test', out['y_test'][:5])\n",
    "print('y test original', outdata['y_test_original'][:5])\n",
    "# print('Counter y test original', --)\n",
    "# print('Counter predict classes', --)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter y test original Counter({'C': 91876})\n",
      "Counter predict classes Counter({2: 91876})\n",
      "1\n",
      "(91876, 4)\n"
     ]
    }
   ],
   "source": [
    "# - ok darn looks like the input data looks corrupt since theres just one class represented\n",
    "print('Counter y test original', Counter(outdata['y_test_original']))\n",
    "print('Counter predict classes', Counter(predict_classes))\n",
    "print(len(Counter(outdata['y_test_original'])))\n",
    "print (outdata['y_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building training set 2019-05-16 15:28:22\n",
      "Start building testing set 2019-05-16 15:28:23\n"
     ]
    }
   ],
   "source": [
    "# ...\n",
    "outdata = make_data(df, crews={'training': [1],\n",
    "                        'test': [2]},\n",
    "              sequence_window=256, row_cap_per_person=None,\n",
    "             feature_cols={'r': simple_scaler})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447652, 7)\n",
      "A    235891\n",
      "C    180853\n",
      "D     23219\n",
      "B      7689\n",
      "Name: event, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1748.640625"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outdata['traindf'].shape)\n",
    "print(outdata['traindf'].event.value_counts())\n",
    "\n",
    "447652/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are not enough sequences. Only ~91876 , \n",
    "# - but should be  around  447652 - 256 . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay so since there are 9 crews in this data , and indeed I assume the test data \n",
    "#     crews are the same people. Anyway, not too important for now.\n",
    "#     But I can split the data into 6 for train and 3 for testing.\n",
    "#\n",
    "# - So as a preliminary simple model, I want to just use the `r` , the respiration data.\n",
    "# - And I suppose it doesn't really matter all too much if both crew member data\n",
    "#      are intermingled, but I think I will split that away for now.\n",
    "\n",
    "encode_class = np.vectorize(lambda x: {'A': 0,\n",
    "                                      'B': 1,\n",
    "                                      'C': 2,\n",
    "                                      'D': 3}.get(x))\n",
    "\n",
    "simple_scaler = lambda x, a: x*a \n",
    "\n",
    "def timestamp():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def do_standard_scaling(df, cols, scalar_dict=None):\n",
    "    if scalar_dict is None:    \n",
    "        scalar_dict = {col: StandardScaler().fit(df[[col]]) for col in cols}\n",
    "        \n",
    "    for col in cols:\n",
    "        df[col + '_scaled'] = np.resize(\n",
    "            scalar_dict[col].transform(df[[col]]),\n",
    "            (df.shape[0],))\n",
    "    \n",
    "    return scalar_dict, df\n",
    "\n",
    "\n",
    "def make_data(df, crews={'training': [1],\n",
    "                        'test': [2]},\n",
    "              sequence_window=256, row_cap_per_person=None,\n",
    "             feature_cols={'r': 'standard_scaler'}):\n",
    "\n",
    "    # current sorted as ['crew', 'experiment', 'time']\n",
    "    [0, 1] # each seat\n",
    "    ['CA', 'DA', 'SS'] # experiment\n",
    "    \n",
    "    sort_cols = ['crew', 'seat', 'experiment', 'time']\n",
    "    target_col = 'event'\n",
    "    \n",
    "    what_cols = sort_cols + list(feature_cols) + [target_col]\n",
    "\n",
    "    # Training\n",
    "    traindf = df[df.crew.isin(crews['training'])][what_cols].sort_values(\n",
    "        by=sort_cols).copy()\n",
    "    \n",
    "    scalar_dict, _ = do_standard_scaling(traindf, ['r'])\n",
    "    \n",
    "    print('Start building training set', timestamp())\n",
    "    x_train, y_train = get_windows(traindf, ['r_scaled', 'event'],\n",
    "                                   sequence_window)\n",
    "    \n",
    "    # Testing\n",
    "    testdf = df[df.crew.isin(crews['test'])][what_cols].sort_values(\n",
    "        by=sort_cols).copy()\n",
    "\n",
    "    _, _ = do_standard_scaling(testdf, ['r'], scalar_dict)\n",
    "    \n",
    "    \n",
    "    print('Start building testing set', timestamp())\n",
    "    x_test, y_test = get_windows(testdf, ['r_scaled', 'event'],\n",
    "                                 sequence_window)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"x_train\": x_train,\n",
    "        \"y_train\": reshape_y(encode_class(y_train), 4), # y_train,\n",
    "        \"x_test\": x_test,\n",
    "        \"y_test\": reshape_y(encode_class(y_test), 4), # y_test\n",
    "        \"y_train_original\": y_train,\n",
    "        \"y_test_original\": y_test,\n",
    "        \"traindf\": traindf,\n",
    "        \"testdf\": testdf,\n",
    "    }\n",
    "\n",
    "\n",
    "def runner():\n",
    "    print('Start make_data', timestamp())\n",
    "    outdata = make_data(df, crews={'training': [1],\n",
    "                        'test': [2]},\n",
    "              sequence_window=256, row_cap_per_person=None,\n",
    "             feature_cols={'r': simple_scaler})\n",
    "    \n",
    "    validate_data(outdata)\n",
    "\n",
    "    print('Start bake_model', timestamp())\n",
    "    model = bake_model(**outdata, epochs=2)\n",
    "    return outdata, model\n",
    "\n",
    "def validate_data(data):\n",
    "    assert len(Counter(data['y_train_original'])) > 1\n",
    "    assert len(Counter(data['y_test_original'])) > 1\n",
    "  \n",
    "    \n",
    "def get_windows(df, cols, window_size):\n",
    "    #\n",
    "    windows = []\n",
    "    Y = []\n",
    "    choices = (df.crew.unique().tolist(), [0, 1], ['CA', 'DA', 'SS'])\n",
    "    for crew, seat, experiment in itertools.product(*choices):\n",
    "        query = (df.crew == crew)&(df.seat == seat)&(df.experiment == experiment)\n",
    "        thisdf = df[query][cols]\n",
    "        return to_sequences(thisdf.values, window_size) \n",
    "        # y = thisdf.iloc[-1].event\n",
    "\n",
    "# Borrowing parts of this func from \n",
    "# https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class10_lstm.ipynb\n",
    "def to_sequences(obs, seq_size, incols=[0], outcols=[1]):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(obs)-seq_size-1):\n",
    "        #print(i)\n",
    "        window = obs[i:(i+seq_size)][..., 0]\n",
    "        after_window = obs[i+seq_size, 1] # FIXME :off by 1 error here?\n",
    "        # window = [[x] for x in window]\n",
    "\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    xarr = np.array(x)\n",
    "    yarr = np.array(y)\n",
    "    return (np.resize(xarr, xarr.shape + (1,)),\n",
    "            yarr)\n",
    "\n",
    "def bake_model(x_train, y_train, x_test, y_test, epochs=1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2,\n",
    "                   input_shape=(None, 1)))\n",
    "    # model.add(Dense(32))\n",
    "\n",
    "    # 4 because 'A', 'B', 'C', 'D'.\n",
    "    model.add(Dense(4))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # initial_state ... for the LSTM , hmm\n",
    "\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...', timestamp())\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#arguments_8\n",
    "    # - hmm so fit() can take a generator sometimes.\n",
    "    # - use_multiprocessing=True \n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "              callbacks=[monitor], verbose=2, epochs=epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def reshape_y(y, num_cols):\n",
    "\n",
    "    # y = np.array([1,2,3,2,3,1],dtype=np.int32)\n",
    "\n",
    "    # Convert y2 to dummy variables\n",
    "    y2 = np.zeros((y.shape[0], num_cols), dtype=np.float32)\n",
    "    y2[np.arange(y.shape[0]), y] = 1.0\n",
    "    return y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
