{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import itertools\n",
    "import ipdb\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mytf.s3utils as msu\n",
    "import mytf.utils as mu\n",
    "import mytf.validation as mv\n",
    "import mytf.plot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_0', 'X_1', 'X_2', 'X_3', 'Ylabels_0', 'Ylabels_1', 'Ylabels_2', 'Ylabels_3'] ['X_0', 'X_1', 'X_2', 'X_3', 'Ylabels_0', 'Ylabels_1', 'Ylabels_2', 'Ylabels_3']\n"
     ]
    }
   ],
   "source": [
    "workdir = 'history/2020-02-03T000055Z'\n",
    "balanced_one_loc = f'{workdir}/balanced_one.h5'\n",
    "balanced_two_loc = f'{workdir}/balanced_two.h5'\n",
    "print(mu.h5_keys(balanced_one_loc), mu.h5_keys(balanced_two_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah history/2020-02-03T000055Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as per [earlier notebook](https://github.com/namoopsoo/aviation-pilot-physiology-hmm/blob/master/notes/2020-02-01.md#shuffle-also)  , going to shuffle these together and make new train/test split datasets..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs1 = [mu.read_h5_two(\n",
    "                source_location=balanced_one_loc, \n",
    "                Xdataset=f'X_{i}',\n",
    "                Ydataset=f'Ylabels_{i}')\n",
    "                 for i in [0, 1, 2, 3]]\n",
    "vecs2 = [mu.read_h5_two(\n",
    "                source_location=balanced_two_loc, \n",
    "                Xdataset=f'X_{i}',\n",
    "                Ydataset=f'Ylabels_{i}')\n",
    "                 for i in [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = list(zip(vecs1, vecs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15713, 64, 8), (15713,)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in vecs1[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(15713, 64, 8), (15713,)], [(20896, 64, 8), (20896,)]]\n",
      "(36609, 64, 8)\n",
      "(36609,)\n"
     ]
    }
   ],
   "source": [
    "# np.concatenate()\n",
    "print([[x[0].shape, x[1].shape] for x in vecs[0]])\n",
    "print(np.concatenate([x[0] for x in vecs[0]]).shape)\n",
    "print(np.concatenate([x[1] for x in vecs[0]]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.concatenate([x[0] for x in vecs[i]])\n",
    "      for i in range(4)]\n",
    "Y = [np.concatenate([x[1] for x in vecs[i]])\n",
    "      for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36609, 64, 8), (36609,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36609, 64, 8), (22996, 64, 8), (29808, 64, 8), (23761, 64, 8)]\n",
      "[(36609,), (22996,), (29808,), (23761,)]\n",
      "(18304,) (18305,)\n",
      "(11498,) (11498,)\n",
      "(14904,) (14904,)\n",
      "(11880,) (11881,)\n",
      "Xtrain: [(18304, 64, 8), (11498, 64, 8), (14904, 64, 8), (11880, 64, 8)]\n",
      "Ytrain: [(18304,), (11498,), (14904,), (11880,)]\n",
      "Xtest: [(18305, 64, 8), (11498, 64, 8), (14904, 64, 8), (11881, 64, 8)]\n",
      "Ytest: [(18305,), (11498,), (14904,), (11881,)]\n"
     ]
    }
   ],
   "source": [
    "# Randomly assign half to train... and the rest to test\n",
    "fullsize = X[0].shape[0]\n",
    "\n",
    "print([a.shape for a in X])\n",
    "print([a.shape for a in Y])\n",
    "\n",
    "def split_indices(A):\n",
    "    fullsize = A.shape[0]\n",
    "    train_size = fullsize//2\n",
    "    train_indices = np.random.choice(range(fullsize), size=train_size, replace=False)\n",
    "    #np.array(list(set(range(5)) - set(np.array([1,2])))), set(train_indices[:4])\n",
    "    test_indices = np.array(list(set(range(fullsize)) - set(train_indices)))\n",
    "    print(train_indices.shape, test_indices.shape)\n",
    "    assert fullsize == train_indices.shape[0] + test_indices.shape[0]\n",
    "    assert fullsize == len(set(train_indices) | set(test_indices))\n",
    "    return train_indices, test_indices\n",
    "\n",
    "indices = [split_indices(A) for A in X]\n",
    "\n",
    "Xtrain = [X[i][indices[i][0]] for i in range(4)]\n",
    "Ytrain = [Y[i][indices[i][0]] for i in range(4)]\n",
    "print('Xtrain:', [A.shape for A in Xtrain])\n",
    "print('Ytrain:', [A.shape for A in Ytrain])\n",
    "\n",
    "Xtest = [X[i][indices[i][1]] for i in range(4)]\n",
    "Ytest = [Y[i][indices[i][1]] for i in range(4)]\n",
    "print('Xtest:', [A.shape for A in Xtest])\n",
    "print('Ytest:', [A.shape for A in Ytest])\n",
    "\n",
    "# Shuffle the X though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainall = np.concatenate([a for a in Xtrain])\n",
    "Y_trainall = np.concatenate([a for a in Ytrain])\n",
    "\n",
    "# Shuffle...\n",
    "size = X_trainall.shape[0]\n",
    "indices = np.random.choice(range(size), size=size, replace=False)\n",
    "X_train_shfl = X_trainall[indices]\n",
    "Ylabels_train_shfl = Y_trainall[indices].astype('int64')\n",
    "\n",
    "\n",
    "# SAVE ...\n",
    "mu.save_that(save_location=f'{workdir}/train_scaled_balanced_shuffled.h5', \n",
    "             name='X', X=X_train_shfl)\n",
    "\n",
    "mu.save_that(save_location=f'{workdir}/train_scaled_balanced_shuffled.h5', \n",
    "             name='Ylabels', X=Ylabels_train_shfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save test, unshuffled\n",
    "#                Xdataset=f'X_{i}',\n",
    "#                Ydataset=f'Ylabels_{i}')\n",
    "[mu.save_that(save_location=f'{workdir}/train_balanced.h5',\n",
    "                name=f'X_{i}', X=Xtrain[i])\n",
    " for i in range(4)]\n",
    "[mu.save_that(save_location=f'{workdir}/train_balanced.h5',\n",
    "                name=f'Ylabels_{i}', X=Ytrain[i])\n",
    " for i in range(4)]\n",
    "\n",
    "\n",
    "# And test too..\n",
    "[mu.save_that(save_location=f'{workdir}/test_balanced.h5',\n",
    "                name=f'X_{i}', X=Xtest[i])\n",
    " for i in range(4)]\n",
    "[mu.save_that(save_location=f'{workdir}/test_balanced.h5',\n",
    "                name=f'Ylabels_{i}', X=Ytest[i])\n",
    " for i in range(4)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_0',\n",
       " 'X_1',\n",
       " 'X_2',\n",
       " 'X_3',\n",
       " 'Ylabels_0',\n",
       " 'Ylabels_1',\n",
       " 'Ylabels_2',\n",
       " 'Ylabels_3']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.h5_keys('history/2020-02-02T044441Z/test_balanced.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
